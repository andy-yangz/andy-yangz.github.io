
 <!DOCTYPE HTML>
<html lang="Chinese, English">
<head>
  <meta charset="UTF-8">
  
    <title>Andy</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Andy Yang">
    

    
    <meta name="description" content="深度学习，自然语言处理攻城狮，爱好广泛，欢迎勾搭。">
<meta property="og:type" content="website">
<meta property="og:title" content="Andy">
<meta property="og:url" content="https://andy-yangz.github.io/index.html">
<meta property="og:site_name" content="Andy">
<meta property="og:description" content="深度学习，自然语言处理攻城狮，爱好广泛，欢迎勾搭。">
<meta property="og:locale" content="Chinese, English">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Andy">
<meta name="twitter:description" content="深度学习，自然语言处理攻城狮，爱好广泛，欢迎勾搭。">

    
    <link rel="alternative" href="/atom.xml" title="Andy" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Andy" title="Andy"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Andy">Andy</a></h1>
				<h2 class="blog-motto">I&#39;m a Master student in Natural Language Processing and an algorithm engineer at TrioTech. I blog about Machine Learning, Deep Learning, and NLP.</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:andy-yangz.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/09/13/论文笔记：Sequence-to-Dependency-Neural-Machine-Translation/" title="论文笔记：Sequence-to-Dependency Neural Machine Translation" itemprop="url">论文笔记：Sequence-to-Dependency Neural Machine Translation</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2018-09-13T00:17:27.641Z" itemprop="datePublished"> Published 2018-09-13</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ol>
<li><h4 id="文章有什么贡献？"><a href="#文章有什么贡献？" class="headerlink" title="文章有什么贡献？"></a>文章有什么贡献？</h4><p>提出了一种新的 Sequence-to-Dependency Neural Machine Translation (SD-NMT)的方法，来将目标语言句法知识利用进了NMT系统，相比起没有使用句法知识的基准NMT系统，性能得到了相对的提高。</p>
</li>
<li><h4 id="研究的问题有何价值？"><a href="#研究的问题有何价值？" class="headerlink" title="研究的问题有何价值？"></a>研究的问题有何价值？</h4><p>目前的NMT系统主要是直接用线性RNN来进行Seq2Seq，但是这样的系统对于捕捉不明显的长距离词的依存还是有很大难度的。因此在解码的时候，将句法知识考虑进解码器中后，可以提高翻译结果语法的正确性，并且也可以利用局部依存信息来生成之后的词语。</p>
</li>
<li><h4 id="研究问题有什么挑战？"><a href="#研究问题有什么挑战？" class="headerlink" title="研究问题有什么挑战？"></a>研究问题有什么挑战？</h4><p>一，如何利用RNN来构建句法结构；<br>二，如何在一个神经网络中，有效地同时进行词语生成，还有句法结构的构建；<br>三，如何有效地利用目标语言的句法背景，来帮助词语的生成。</p>
</li>
<li><h4 id="本文的解决思路？"><a href="#本文的解决思路？" class="headerlink" title="本文的解决思路？"></a>本文的解决思路？</h4></li>
</ol>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-594358846a37bbbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>一，利用了两个RNN网络，Action RNN 和 Word RNN，分别进行词语生成和句法结构的构建。Action RNN 利用了transition-based dependency parsing (基于转换的依存句法分析) 中的 arc-standard shift-reduce algorithm 算法，来生成构建所需依存结构的动作。而同时因为两个 RNN 生成的的序列长度不一致，所以 Word RNN 利用了些技巧，使得它能够参考 Action RNN 的结果输出词语，或者保持不变以和 Action RNN 的时序保持一致。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-d49d4d5947999b68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>二，通过定义生成依存结构时的栈顶部两个词语，最左和最右修饰语的一元和二元语言特征，生成相对当前词汇的局部依存背景。之后将这个背景与 Word RNN 的输出结合起来，帮组生成新的词汇。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NMT/">NMT</a><a href="/tags/Linguistic-Structure/">Linguistic Structure</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/09/13/论文笔记：LSTM-A-Search-Space-Odyssey/" title="论文笔记：LSTM： A Search Space Odyssey" itemprop="url">论文笔记：LSTM： A Search Space Odyssey</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2018-09-13T00:17:27.641Z" itemprop="datePublished"> Published 2018-09-13</time>
    
  </p>
</header>
    <div class="article-content">
        
        <ol>
<li><h4 id="文章有何贡献？"><a href="#文章有何贡献？" class="headerlink" title="文章有何贡献？"></a>文章有何贡献？</h4><p>是第一个对LSTM还有它的八种变体进行大规模调查的论文。</p>
</li>
<li><h4 id="本文研究的问题有何价值？"><a href="#本文研究的问题有何价值？" class="headerlink" title="本文研究的问题有何价值？"></a>本文研究的问题有何价值？</h4><p>本文填补了对LSTM的各组件进行系统性调查的空缺，而且一定程度上系统性的解决了如何提高LSTM架构性能的开放性问题。也为之后的研究者如何更好的使用LSTM，理解LSTM，已经调节其参数提供了很好的建议。</p>
</li>
<li><h4 id="本文概要"><a href="#本文概要" class="headerlink" title="本文概要"></a>本文概要</h4></li>
</ol>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-ceab00ad6f9d87bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>标准的LSTM主要是由这几个部分，三个门：input gate、 forget gate、 output gate， 还有输入块与输出块。<br>首先调查的是对这几个门进行修改的变体：<br>NIG: No Input Gate 没有输入门<br>NFG: No Forget Gate 没有遗忘门<br>NOG: No Output Gate 没有输出门<br>NIAF: No Input Activation Function 没有输入块激活函数<br>NOAF: No Output Activation Function 没有输出块的激活函数<br>CIFG: Coupled Input and Forget Gate 耦合的输入和遗忘门<br>还有就是两个在LSTM上的小技巧，一个是Peephole（窥视孔），利用cell的状态来给予几个门更多的提示；还有一个是全门循环连接，也就是说通常的门是包含在LSTM单元里面输出端不直接和下一个单元交流的，但是全门连接表示将每个单元之间的门也直接连接起来。<br>NP: No Peephole 没有窥视孔<br>FGR: Full Gate Recurrence 全门循环连接</p>
<p>加上标准LSTM总共9个。在三个任务上进行测试，分别是：语言识别，手写识别，还有复调音乐模型建立。<br>对于每个模型还要对以下几个参数进行探索：LSTM的隐藏单元数，学习率，动量 (momentum)，高斯输入噪音。</p>
<ol start="4">
<li><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p>一、各变体的比较。<br>标准LSTM结构在各个数据集上都能表现出较好的结果，而各个变体也并没有显著地提高了LSTM的性能。<br>还有即使加入了输入门和遗忘门的耦合，或是移除了窥视孔设置，也并不会很大程度上降低性能，同时这两个设置还减少了LSTM的计算量。<br>根据实验数据，还得出LSTM中，遗忘门和输出激活函数是最关键的组件。<br>二、各参数的影响<br>学习率是最关键的超参数，然后是网络的大小。而让人惊讶的是，动量在这几个试验中并没有很重要。<br>还有高斯噪音的加入，根据任务的不同有时有帮助，有时却会有害。<br>在对超参数之间的互相作用进行调查时，它们并没有表现出明显的结构性关系，甚至可以忽略其的影响。所以我们可以假设这些超参数是大概相对独立的。<br>还有一个关于学习率的建议，对于一个数据集，可以先用一个小的网络找到一个好的学习率，然后把它用到大的网络中去。</p>
</li>
<li><h4 id="我的评价"><a href="#我的评价" class="headerlink" title="我的评价"></a>我的评价</h4><p>虽然在这篇论文中得到了关于LSTM的很多建议，但根据自己的实际实验，却有一些是和它的结论不怎么吻合的。<br>首先是我之前有碰到过，变大网络反而使得性能变差，而这篇论文中是说只会提高性能。<br>还有关于超参数之间的关系，我也有碰到分别调两个都可以提高性能，但是一结合就降低了性能的。<br>最后一点建议是，这篇论文虽然对输入噪音进行了调查，却没有对RNN的dropout进行调查，可能这个也能作为一个探索点。<br>看完本文之后还是觉得LSTM有很多很多谜团。</p>
</li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/LSTM/">LSTM</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/12/25/神经机器翻译概览：基准模型与改进（上）/" title="神经机器翻译概览：基准模型与改进（上）" itemprop="url">神经机器翻译概览：基准模型与改进（上）</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-12-25T02:02:29.000Z" itemprop="datePublished"> Published 2017-12-25</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>最近一段时间在研究的一些东西。</p>
<p>介绍一下当前机器翻译领域很火的神经机器翻译(<strong>Neural Machine Translation</strong> ，简称<strong>NMT)</strong>领域的大致状况，最近的一些进展（内容主要来自<strong>Philipp Koehn</strong>的 <strong><em>Statistical Machine Translation</em></strong> 还未发布的草稿，想了解更详细内容，读<a href="https://arxiv.org/pdf/1709.07809.pdf" target="_blank" rel="noopener">原文</a>)。</p>
<p>首先什么是机器翻译？</p>
<p>显而易见就是<strong>用机器来翻译</strong>，这里机器说的是计算机了。终极目标是抢走翻译们的饭… 噢，不对，是消除人们的交流沟通障碍，促进世界人民大团结！</p>
<p>那神经机器翻译又是什么鬼？</p>
<p>首先机器翻译是个大目标，达到目标有很多种方法。比如说神经机器翻译之前，很流行用统计方法来搭建机器翻译系统，这叫做<strong>统计机器翻译</strong> (Statistical Machine Translation SMT)。</p>
<p>同样的如果用神经网络方法来达成机器翻译这个目标，那么就叫神经机器翻译。</p>
<p>为什么现在神经机器翻译很火呢？ </p>
<p>第一，在自然语言处理中，<strong>机器翻译是一个高级问题</strong>，这意味着解决这个问题，还能顺带把方法用到很多其他问题上去。比如说现在广泛使用的注意力机制 (Attention Mechanism)，最早就是先在机器翻译系统使用的。并且机器翻译<strong>非常实用</strong>，想想你看不懂论文时打开谷歌翻译时，就知道了。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-c9b0ed638057d8c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>第二，还有现在深度学习大火，<strong>神经网络也确实在机器翻译上取得很好的成绩</strong>，比起之前统计机器翻译中效果最好的模型（基于短语的统计机器翻译模型）都能强出很多。这也是为什么现在谷歌翻译基本上都已经换成神经机器翻译模型了。</p>
<p>好了，这就是背景知识了。那么先来讲讲现在使用最普遍的基准模型吧。</p>
<h2 id="基准模型（seq2seq-attention）"><a href="#基准模型（seq2seq-attention）" class="headerlink" title="基准模型（seq2seq+attention）"></a>基准模型（seq2seq+attention）</h2><p><img src="http://upload-images.jianshu.io/upload_images/4787675-87db57aaaadf12a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>现在最常用的基准模型如上图，主体部分主要由三部分组成，编码器(Encoder)、解码器(Decoder)、还有注意力机制(Attention)。</p>
<p><strong>编码器</strong>：编码器其实很好理解，就把它当做一个总结器，输入一段源语言句子(比如说英文的I love you.)，那么编码器就是把这句话的信息总结出来。可以理解为人读完一句话，然后总结成一个模糊的意思。</p>
<p><strong>解码器</strong>：然后解码器根据编码器传过来的信息，来把这个信息用目标语言表示出来，也就是翻译出来。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-6ae261d23593e48e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><strong>注意力机制：</strong>如果单靠一次总结后直接解码翻译的话，效果并不好。所以可以再像人一样，边翻译同时再回看源语言每个词的信息，之后也能知道更准确的词和词的对应关系。上图就是英法翻译时，词对应情况。</p>
<p>之后输入输出部分就主要由<strong>词向量表</strong>和<strong>预测模块</strong>组成了。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-5026fd46e7fc5f4e.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>整个翻译流程像这样，输入源语言（比如说汉语），转换成词向量，传入编码器编码总结，然后传给解码器，解码器通过注意力机制，一个词一个词，边参考源语言信息边翻译成目标语言（比如说英语），最后用到柱搜索 (Beam Search，感兴趣自己去搜搜看) 算法选出最好的备选翻译。</p>
<p>这就是目前神经机器学习的基准模型了。</p>
<p>基准模型学习资源（流行框架）：</p>
<ul>
<li><a href="https://github.com/tensorflow/nmt" target="_blank" rel="noopener">TensorFlow NMT Tutorial</a></li>
<li><a href="https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb" target="_blank" rel="noopener">PyTorch NMT Tutorial</a></li>
</ul>
<h3 id="基准模型改进"><a href="#基准模型改进" class="headerlink" title="基准模型改进"></a>基准模型改进</h3><p>当然这个领域还在不停地发展，因此每年也会不断有很多提高基准模型的方法被发表出来，特别是在每年<a href="http://www.statmt.org/wmt17/" target="_blank" rel="noopener"><strong>WMT</strong></a>（相当于机器翻译领域每年的华山论贱）大赛上都会有队伍将最有效地一些方法进行总结，然后实现到实际模型上来。</p>
<p>这些方法也都很有意思，之后就一一来介绍。</p>
<h4 id="集成解码方法-Ensemble-Decoding"><a href="#集成解码方法-Ensemble-Decoding" class="headerlink" title="集成解码方法(Ensemble Decoding)"></a>集成解码方法(Ensemble Decoding)</h4><p>首先是比较容易理解的集成解码，实际上就是一句话<strong>人多力量大</strong>。</p>
<p>既然一个模型的准确率不行，那么就几个不同的模型一起用，因为每个模型可能都会有些差异，有不同的缺点，如果用多个模型的话，就能产生互补效应，获得更好的翻译效果。</p>
<p>但是集成也根据集成模型的不同分为以下几种。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-fdfbda836a5df1df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h5 id="检查点（checkpoint）集成"><a href="#检查点（checkpoint）集成" class="headerlink" title="检查点（checkpoint）集成"></a><strong>检查点（checkpoint）集成</strong></h5><p>检查点就相当于游戏中的存档点，将模型训练到一定程度，然后希望把当前模型的所有参数保持下来，以便之后使用。一般检查点会以epoch（整个数据集过一遍）、iteration（一次批训练更新权重）、或者句子数为单位，比如说epoch15模型就是训练完15个epoch的模型。</p>
<p>而检查点集成就是，<strong>用这些不同时间点保存下来的模型一起来预测</strong>。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-7183e2e8fa4af1bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h5 id="多次运行-Multi-run-集成"><a href="#多次运行-Multi-run-集成" class="headerlink" title="多次运行 (Multi-run) 集成"></a><strong>多次运行 (Multi-run) 集成</strong></h5><p>多次运行集成有好几种情况。</p>
<p>可以是<strong>同一个模型，以不同的初始条件来运行</strong>，最后得到的多个模型；也可以是<strong>不同的模型</strong>，在用一个数据集上训练，最后得到的多个模型。</p>
<h5 id="利用从右到左模型重排序解码"><a href="#利用从右到左模型重排序解码" class="headerlink" title="利用从右到左模型重排序解码"></a>利用从右到左模型重排序解码</h5><p>目前一般的解码器都是从左到右地一个词一个词地译出目标语言，所以一般RNN解码器都是单方向的，但编码器都是双方向以获得更多的信息。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-d101ecb327c1be73.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>为了让解码器也能利用双方向的信息，可以训练一个模型反过来翻译目标语言，从右到左输出结果，比如说“我爱你”翻译成英文，按这样的顺序来译“you -&gt; love -&gt; I.”。</p>
<p>之后用从右到左的模型输出的结果，来筛选从左到右模型输出的结果，就可以获得更好的翻译。</p>
<p>当然上面这些集成方法也可以都用上，一起集成输出结果当然更好，但同时也会导致<strong>运算成本过高</strong>的问题，毕竟一个模型训练下来就要很久了，更何况几个了。</p>
<h4 id="处理大词汇量"><a href="#处理大词汇量" class="headerlink" title="处理大词汇量"></a>处理大词汇量</h4><p>对于NMT，其中一个最大的难题就是<strong>如何处理庞大的词汇量</strong>。</p>
<p>因为神经网络方法一般处理词汇是建立词向量表，之后通过查表将句子转换成词向量。也就是对于词向量表，每个不同的词就对应一个不同的向量。对于有些语言，因为形态学(Morphology)比较复杂，所以一个词可能会有很多很多种变形，即使意思并没差太多，这样的语言词汇量却会非常大。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-eb5e1b10ba9fe7c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>对于编码器端，会导致<strong>词向量表非常大</strong>，同时因为可能某些形态的词在整个数据集中只出现很少的次数，所以会<strong>导致稀疏问题，某些词向量根本没得到充足的训练</strong>。</p>
<p>而对于解码器端，因为输出时会用softmax来进行概率输出，从目标语言词汇中挑选出合适的词。这会导致<strong>过大的计算量</strong>，也是一个大问题。</p>
<p>目前大家能想到的解决这个问题的方法是，使用<strong>子词 (sub-word) </strong>而不是词(Word)来进行翻译，比如说英文里面 unhappy = un + happy.</p>
<p>对于人来说，因为语言本能，这些都可以自然而然在脑中解构。但对于计算机就不行，得我们告诉它怎么做。</p>
<h5 id="字节对编码-Byte-Pair-Encoding-BPE-法"><a href="#字节对编码-Byte-Pair-Encoding-BPE-法" class="headerlink" title="字节对编码 (Byte Pair Encoding, BPE) 法"></a>字节对编码 (Byte Pair Encoding, BPE) 法</h5><p>现在使用比较广泛的一个方法是BPE法，因为爱丁堡大学的<strong>Nematus</strong>系统用这个取得了很好的效果。</p>
<p>原理的话出乎意料，和语言学没有关系，也并不是很难。主要步骤如下。</p>
<ol>
<li>将训练数据中所有词都表示成字节，把这些字节加入符号表，最开始大概是a, b, c…还有各种符号；</li>
<li>然后统计符号对的出现频率，比如说th, zt…；</li>
<li>挑出其中频率最高的符号对，加入符号表，训练数据集中所有该符号对融合，比如说t和h全变成了th。这个叫做一次融合，之后重复2,3过程，直到指定的融合次数。</li>
</ol>
<p>比如说爱丁堡大学在WMT16比赛中就用了89500次融合。完成这个BPE学习之后，用它来处理训练数据集，之后直接在bpe之间翻译，这样可以大大降低了词汇量。</p>
<h3 id="使用单语言数据"><a href="#使用单语言数据" class="headerlink" title="使用单语言数据"></a>使用单语言数据</h3><p>机器翻译里面训练数据之所以难收集，主要是因为它用的是<strong>并列数据 (parallel data)</strong>，也就是源语言和目标语言之间，一句话一句话得对应起来。因此准备数据的过程特别麻烦，所以对于深度学习这种数据越多越好的模型，有时候可能数据也并不够。</p>
<p>但同时另一方面，单独的语言数据我们又不缺，随便在网上抓一抓就很多很多。因此如何利用这些单语言数据就成了一个热门研究方向。</p>
<p>这里列举几个比较成功的方法。主要分为增加训练数据和训练语言模型来辅助翻译。</p>
<h5 id="回译"><a href="#回译" class="headerlink" title="回译"></a>回译</h5><p>回译的要点是，<strong>既然训练数据不足，那么就合成数据</strong>。但是怎么样合成呢？</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-f435c0d7a37e7ff4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这里假设我们有大量的目标语言单语言数据，那么为什么不建立一个反向的翻译系统，将这些目标语言翻译成源语言，之后再用获得的并行数据来训练所需要的系统呢。</p>
<p>这也是为什么这个技巧的名字叫做”<strong>回译 (Back Translation)</strong>“。</p>
<h4 id="加入语言模型"><a href="#加入语言模型" class="headerlink" title="加入语言模型"></a>加入语言模型</h4><p>首先什么是语言模型？一句话，<strong>训练一个模型，然后这个模型判断你说不说的是人话</strong>，这就是语言模型，很简单吧。</p>
<p>比方说我用脸打出来的“过以风格黑哦豆腐干会双方各黑分两个覅”就不是人话，你估计也不可能再在其他地方看到这样的句子了；而“我吃饭了”，这样正常的、有意义的、随处可见的话就是人话了。</p>
<p>而加入语言模型主要就是判断解码器翻译出来的是不是人话，从而帮助解码器获得更好的翻译效果。</p>
<p>至于如何学习怎么判断说的是不是人话，也就是训练语言模型，只要读书破万卷就可以了，把单语言数据丢给语言模型让自己训练就好了。</p>
<h4 id="往返训练"><a href="#往返训练" class="headerlink" title="往返训练"></a>往返训练</h4><p><img src="http://upload-images.jianshu.io/upload_images/4787675-84693fdf68e59339.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>最后是往返训练，就是把回译的技巧用来同时训练两个模型。比如上图一个模型是从 f-&gt;e（法译英），而另一个是反过来的英译法。</p>
<p>往返训练的流程是这样子的，假设我们有f单语言数据，那么先用正向模型翻译成e’，之后用这个e‘和f来训练反向模型。当要用e的单语言数据，只要反过来操作就好了。</p>
<p>这样子两个好基友互相训练♂♂，最终就能都成为好模型。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural Language Processing</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NLP/">NLP</a><a href="/tags/机器翻译/">机器翻译</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/07/11-7论文笔记Predicting-Target-Language-CCG-Supertags-Improves-Neural-Machine-Translation/" title="论文笔记:Predicting Target Language CCG Supertags Improves Neural Machine Translation" itemprop="url">论文笔记:Predicting Target Language CCG Supertags Improves Neural Machine Translation</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-11-07T14:14:14.000Z" itemprop="datePublished"> Published 2017-11-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="一、文章有什么贡献？"><a href="#一、文章有什么贡献？" class="headerlink" title="一、文章有什么贡献？"></a>一、文章有什么贡献？</h4><ol>
<li>主要共享是提出了一个新的思路，以CCG (Combinatory Categorial Grammar) Supertag的形式将句法信息引入了，NMT（神经机器翻译）的解码器端，对NMT的性能有了一定提高。</li>
<li>用两种方式将CCG Supertag任务引入解码器，一种是直接插入输出的序列，一种是利用了多任务学习，对多任务学习的研究也有一些贡献。</li>
<li>展示了不光是解码器，当同时在编码器端输入语言学信息的时候，性能得到进一步提高。</li>
<li>对其中更多细节，如句子种类还有句子长度也进行了详细的分析。进一步理解，引入语言学信息后对NMT系统的影响。</li>
</ol>
<h4 id="二、本文研究问题有什么价值？"><a href="#二、本文研究问题有什么价值？" class="headerlink" title="二、本文研究问题有什么价值？"></a>二、本文研究问题有什么价值？</h4><p>首先引入CCG Supertag来对NMT的解码器加入语法学信息，而且证明了这种情况下直接插入输出序列比多任务学习的性能要好。当然主要还是证明了，语言学对NMT系统的影响。</p>
<h4 id="三、研究问题有什么挑战？"><a href="#三、研究问题有什么挑战？" class="headerlink" title="三、研究问题有什么挑战？"></a>三、研究问题有什么挑战？</h4><p>大概就是如何将CCG supertag的语法信息引入编码器端吧。</p>
<p>之后很多都是对系统的详细分析了。</p>
<h4 id="四、本文解决思路？"><a href="#四、本文解决思路？" class="headerlink" title="四、本文解决思路？"></a>四、本文解决思路？</h4><p>本文提出了两个解决思路。</p>
<ol>
<li><p>一个是interleaving，也就是将CCG supertag直接相间插入目标语言的序列中去，也就是将输出序列长度增加一倍，一个单词一个相应的tag。如这样 $y^{‘}=y_1^{tag},y_1^{word},…,y_T^{tag},y_T^{word}$ .</p>
<p>然后就把这个当做是原来的目标语言序列，进行解码预测。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-9a98cd36e56004d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="interleaving"></p>
</li>
<li><p>还有一种思路是利用多任务学习(Multi-task Learning)，两个解码器分别用来翻译和输出CCG supertag，这两个解码器共享一个编码器。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-0f2176669ea14a6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="multitasking"></p>
<p>结果是第一个方案更好一些。</p>
</li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NMT/">NMT</a><a href="/tags/Linguistic-Structure/">Linguistic Structure</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/07/小黄人语从入门到进精神病院/" title="小黄人语从入门到进精神病院" itemprop="url">小黄人语从入门到进精神病院</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-11-07T14:14:14.000Z" itemprop="datePublished"> Published 2017-11-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>目前，世界上有成千上万的语言被使用着，其中包括：家族语，民族语，部落语等等。而小黄人语（又叫香蕉语），当然也属于其中的一种。虽然，现在没有任何一种语得到了真正的全球化，但可以看见的是，<strong>人工语 (Conlangs) 正在慢慢接管着世界</strong>。</p>
<p>直到今天，世界上已经出现了很多许许多多的人工语。它们是由狂热宅男（没错，说的就是谢耳朵他们。），或是语言专家们构造出来的。大部分人工语一般最早都出现在电影里，接着之后，被粉丝或是语言狂们慢慢传开。</p>
<p>几种耳熟能详的几种人工语：</p>
<ul>
<li>世界语（L.L. Zamenhof 发明） - Mi regas la mondon!</li>
<li>克林贡语 (星际迷航) - nuqneH </li>
<li>帕库尼语（失落大陆） -  Me tobi ye</li>
<li>精灵语（魔戒）- Elen sila lumenn omentilmo</li>
<li>多斯拉克语（权力的游戏，蹭热点中…）- <strong>Athchomar Chomakea!</strong></li>
</ul>
<p><img src="https://thechive.files.wordpress.com/2016/05/34180-daenerys-targaryen-baby-dragon-cibv.gif?w=500" alt="34180 daenerys targaryen baby dragon cibv28 Dothraki phrases all true GOT fans should add to their vocabulary (20 Photos)"></p>
<p>而现在香蕉语也将成为它们中的一员，都叫不明觉厉语。</p>
<h4 id="香蕉语的起源"><a href="#香蕉语的起源" class="headerlink" title="香蕉语的起源"></a>香蕉语的起源</h4><p><img src="http://images.techtimes.com/data/images/full/102658/11018805_895801337108779_8220057388801140003_n-png.png?w=570" alt="img"></p>
<p>根据导演 Pierre Coffin 和 Kyle Balda, 据说他们有一套特别创造语言方法。那就是，把世界上所有语言中听起来好玩的词跳出来，然后再转换成小黄人的腔调，就有了小黄人语了。</p>
<p>至于为什么是世界各个国家的语言，又据说是，小黄人们为了永久不失业，能够服务全世界的大坏蛋，所以才把什么都往里面塞。</p>
<p> 这里举几个例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Gelato - 意大利语的冰淇淋</span><br><span class="line">Kanpai - 日语里的干杯</span><br><span class="line">La boda - 西班牙里的结婚</span><br><span class="line">Hana, Dul, Sae - 欧巴语里的一二三</span><br><span class="line">Kamari - 印尼语的过来</span><br><span class="line">Pwede na - 菲律宾语的可以开始了吗</span><br><span class="line">Kuai dian la - 中文快点啦</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h4 id="香蕉语的基本音标-（Hana-Dul-Sae）"><a href="#香蕉语的基本音标-（Hana-Dul-Sae）" class="headerlink" title="香蕉语的基本音标 （Hana, Dul, Sae）"></a>香蕉语的基本音标 （Hana, Dul, Sae）</h4><p>学日语有五十音，中文有拼音，德语、英语此类也都有自己的字母音标。所以首先，先讲讲音标，这个基本组成部分。</p>
<p><strong>元音</strong>：a, u, o, i, oo, ee, an, aw, ae 欸, ey, oy</p>
<p><strong>辅音</strong>：b, d, p, t, n, m, k, h, st, l, s, g</p>
<p>至于怎么读，基本和汉语拼音是一样的。出现两个同样字母的为长音和德语一样，st 的话连读就可以了。</p>
<p>小黄人语的特征是，语言急促，少长音、浊辅音，还有像sh, th 这样英文中的摩擦音。所以听起来都是叽里呱啦的。</p>
<h4 id="香蕉语的基本用语-Muak-Muak-Muak"><a href="#香蕉语的基本用语-Muak-Muak-Muak" class="headerlink" title="香蕉语的基本用语 (Muak, Muak, Muak)"></a>香蕉语的基本用语 (Muak, Muak, Muak)</h4><p><img src="http://images.techtimes.com/data/images/full/102661/10703624_812612438761003_7120805279350445856_n-jpg.jpg?w=570" alt="img"></p>
<p>首先，无论是哪种语言，最先都得掌握些基本用语吧。所以，先来点用得上的，之后在电影院立刻能拿来装逼。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">你好 - Bello (bello 在意大利语里面是帅哥的意思。顺便教一句，怎么撩意大利小哥。ciao bello, una notte con me . )</span><br><span class="line">再见 - Poopaye</span><br><span class="line">谢谢 - Tank yu</span><br><span class="line">对不起 - Biido</span><br><span class="line">给你 - Para tu</span><br><span class="line">你敢！- Sa la ka！</span><br><span class="line">我发誓(I swear) - Underwear(内衣，绝对是恶搞，哈哈)</span><br><span class="line">我饿了 - Me want banana</span><br><span class="line">我（们）爱你 - Tulaliloo ti amo. (没搞懂tulalillo是什么意思，可能是表示我们吧。ti amo是意大利语里的我爱你)</span><br><span class="line">一二三 - Hana，Dul，Sae</span><br><span class="line">苹果 - Papples</span><br></pre></td></tr></table></figure>
<h4 id="香蕉语更多资源"><a href="#香蕉语更多资源" class="headerlink" title="香蕉语更多资源"></a>香蕉语更多资源</h4><p><img src="http://www.minionsallday.com/wp-content/uploads/2016/03/Dave1-1024x555.png" alt="Dave saying Voila"></p>
<p><strong>音乐</strong></p>
<table>
<thead>
<tr>
<th>原曲</th>
<th>小黄人版</th>
</tr>
</thead>
<tbody>
<tr>
<td>Copacabana (科帕卡巴纳) - Bary Manilow</td>
<td>Bella Banana (你好香蕉) - 小黄人四人组</td>
</tr>
<tr>
<td>I swear (我发誓) - Boyz II Men</td>
<td>Underwear (内衣) - 同上四人组</td>
</tr>
<tr>
<td>YMCA - Village People</td>
<td>YMCA - 同上</td>
</tr>
<tr>
<td>Barbara Ann (芭芭拉 安) - The Beach Boys</td>
<td>Banana Song (香蕉之歌) - 还是同上</td>
</tr>
<tr>
<td>铃儿响叮当 - James Lord Pierpont</td>
<td>铃儿响叮当 - 小黄人逗比军团</td>
</tr>
</tbody>
</table>
<p><strong>黄宝书</strong></p>
<p><img src="http://www.minionsallday.com/wp-content/uploads/2016/03/MINIONESE-ENGLISH-PHRASEBOOK.png" alt="MINIONESE - ENGLISH PHRASEBOOK Infographic"></p>
<p>最后，来造个句。</p>
<p><strong>Ti amo. Underwear. Muak, Muak Muak.</strong> XD</p>
<p><img src="http://1.im.guokr.com/U28ShtQiOj4DFVrtbe_DRyjza9llbr4-LswIQ4IzIUT0AQAACwEAAEdJ.gif" alt="img"></p>
<h4 id="参考文献（这可是正经的研究）"><a href="#参考文献（这可是正经的研究）" class="headerlink" title="参考文献（这可是正经的研究）"></a>参考文献（这可是正经的研究）</h4><ol>
<li><a href="http://www.guokr.com/post/600015/focus/1293681540/" target="_blank" rel="noopener">小黄人语言集合</a></li>
<li><a href="http://www.techtimes.com/articles/64439/20150629/want-learn-minion-language-heres-list-words-english-translation.htm" target="_blank" rel="noopener">Want To Learn Minion Language? Here’s A List Of Minion Words And Their English Translations</a></li>
<li><a href="http://www.minionsallday.com/minionese-language-of-the-minions/" target="_blank" rel="noopener">Minionese, Language of the Minions: Origin, Vocabulary and Grammar</a></li>
<li><a href="http://minionwithadlie.blogspot.jp/" target="_blank" rel="noopener">Minion Dictionary</a></li>
<li><a href="https://www.daytranslations.com/blog/2015/06/the-minions-language-is-a-combination-of-french-spanish-english-and-food-references-6419" target="_blank" rel="noopener">The Minions’ language is a combination of French, Spanish, English… and food references</a></li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/语言学/">语言学</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/恶搞/">恶搞</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/07/11-7-paper-note-2/" title="论文笔记：Understanding Hidden Memories of Recurrent Neural Networks" itemprop="url">论文笔记：Understanding Hidden Memories of Recurrent Neural Networks</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-11-07T08:03:40.000Z" itemprop="datePublished"> Published 2017-11-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="一、文章有何贡献？"><a href="#一、文章有何贡献？" class="headerlink" title="一、文章有何贡献？"></a>一、文章有何贡献？</h4><p>主要贡献有三。</p>
<ol>
<li>设计了RNNVis系统，这是一个用于理解、比较、和诊断自然语言处理任务中RNN的视觉分析系统。</li>
<li>提出一个用期望反应(expected response)来链接RNN中的隐藏状态和文本信息的新技术。</li>
<li>提出了一个图像为基础的序列可视化设计，来分析句子级别的RNN的行为。</li>
</ol>
<h4 id="二、本文研究问题有何价值？"><a href="#二、本文研究问题有何价值？" class="headerlink" title="二、本文研究问题有何价值？"></a>二、本文研究问题有何价值？</h4><p>现在关于神经网络的很多东西我们还并不是很理解，所以都把它当成是一个黑匣子。当然也有过一些对神经网络中捕捉的表达的探索，但主要集中在计算机视觉方面。</p>
<p>主要是因为序列语言中的规则难以视觉化，而且对于其中RNN的机制也很多地方没有理解，这篇论文有望让我们进一步理解RNN黑箱子里面的一些行为，然后对RNN结构进行提高。</p>
<h4 id="三、研究问题有什么挑战？"><a href="#三、研究问题有什么挑战？" class="headerlink" title="三、研究问题有什么挑战？"></a>三、研究问题有什么挑战？</h4><ol>
<li>​</li>
</ol>
<h4 id="四、本文解决思路？"><a href="#四、本文解决思路？" class="headerlink" title="四、本文解决思路？"></a>四、本文解决思路？</h4><ol>
<li><p>对于第一个问题，就如问题，把生成器的StackLSTM替换成NMT的解码器，然后让NMT的解码器作为生成器来和RNNG的其他两个部件，Stack和Action部件进行互动。如每次只有当，Action部件生成Shift指令的时候，才让NMT的解码器预测下一个单词，然后推入Stack中去。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-e6faea7b84f4c40b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="RNNG 模型"></p>
<p>​</p>
<p>关于这个部分具体可以参考RNNG的原论文，重点读Generator Transition那一节。<a href="https://arxiv.org/abs/1602.07776" target="_blank" rel="noopener">Dyer et al., Recurrent Neural Network Grammars</a></p>
</li>
<li><p>对于第二个问题，就是找个比较好的parser，对已有的平行语料库进行标注，然后再训练，也没有太多新颖的地方，却特意提到distillation。</p>
</li>
</ol>
<h4 id="五、讨论"><a href="#五、讨论" class="headerlink" title="五、讨论"></a>五、讨论</h4><p>虽然这篇论文的idea并不是让人惊喜，而且也没有给出模型的图片，还得跑去找RNNG的论文来看。</p>
<p>其中一些具体的实现细节也没提到， 比如是直接把NMT的解码器当做RNNG的生成器，然后进行Joint Training。还是说将Action和Stack的一些信息也作为输入信号输入了NMT的解码器呢，使得NMT的解码器可以进一步的利用获得的语法知识。就如论文 <a href="http://www.aclweb.org/anthology/P17-1065" target="_blank" rel="noopener">Wu, Shuangzhi, et al. Sequence-to-Dependency Neural Machine Translation 2017</a>里面一样。</p>
<p>如果没有提到就是没有利用的话，那么这个思路不妨是个继续探索的方向。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/RNN/">RNN</a><a href="/tags/NLP/">NLP</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/07/论文笔记Learning-to-Parse-and-Translate-Improves-Neural-Machine-Translation/" title="论文笔记:Learning to Parse and Translate Improves Neural Machine Translation" itemprop="url">论文笔记:Learning to Parse and Translate Improves Neural Machine Translation</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-11-07T07:06:16.000Z" itemprop="datePublished"> Published 2017-11-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="一、文章有何贡献？"><a href="#一、文章有何贡献？" class="headerlink" title="一、文章有何贡献？"></a>一、文章有何贡献？</h4><p>提出了一个叫做<strong>NMT (Neural Machine Translation) + RNNG (Recurrent Neural Network Grammars)</strong>的混合模型，这个模型如字面意思将注意力机制的NMT和RNNG进行了结合，可以同时进行dependency parsing和翻译。 </p>
<h4 id="二、本文研究问题有何价值？"><a href="#二、本文研究问题有何价值？" class="headerlink" title="二、本文研究问题有何价值？"></a>二、本文研究问题有何价值？</h4><p>也是将语法知识利用进NMT模型的一篇论文之一，与基线相比提高了一些性能。</p>
<h4 id="三、研究问题有什么挑战？"><a href="#三、研究问题有什么挑战？" class="headerlink" title="三、研究问题有什么挑战？"></a>三、研究问题有什么挑战？</h4><p>大概有两条挑战。实际上感觉挑战并不是很大，只是将之前的RNNG的生成器部分替换成了NMT的解码器。</p>
<ol>
<li>如何将原来的RNNG模型中的生成器的StackLSTM替换成NMT的解码器。</li>
<li>没有标注好parsing的平行语料库。</li>
</ol>
<h4 id="四、本文解决思路？"><a href="#四、本文解决思路？" class="headerlink" title="四、本文解决思路？"></a>四、本文解决思路？</h4><ol>
<li><p>对于第一个问题，就如问题，把生成器的StackLSTM替换成NMT的解码器，然后让NMT的解码器作为生成器来和RNNG的其他两个部件，Stack和Action部件进行互动。如每次只有当，Action部件生成Shift指令的时候，才让NMT的解码器预测下一个单词，然后推入Stack中去。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-e6faea7b84f4c40b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="RNNG 模型"></p>
<p>​</p>
<p>关于这个部分具体可以参考RNNG的原论文，重点读Generator Transition那一节。<a href="https://arxiv.org/abs/1602.07776" target="_blank" rel="noopener">Dyer et al., Recurrent Neural Network Grammars</a></p>
</li>
<li><p>对于第二个问题，就是找个比较好的parser，对已有的平行语料库进行标注，然后再训练，也没有太多新颖的地方，却特意提到distillation。</p>
</li>
</ol>
<h4 id="五、讨论"><a href="#五、讨论" class="headerlink" title="五、讨论"></a>五、讨论</h4><p>虽然这篇论文的idea并不是让人惊喜，而且也没有给出模型的图片，还得跑去找RNNG的论文来看。</p>
<p>其中一些具体的实现细节也没提到， 比如是直接把NMT的解码器当做RNNG的生成器，然后进行Joint Training。还是说将Action和Stack的一些信息也作为输入信号输入了NMT的解码器呢，使得NMT的解码器可以进一步的利用获得的语法知识。就如论文 <a href="http://www.aclweb.org/anthology/P17-1065" target="_blank" rel="noopener">Wu, Shuangzhi, et al. Sequence-to-Dependency Neural Machine Translation 2017</a>里面一样。</p>
<p>如果没有提到就是没有利用的话，那么这个思路不妨是个继续探索的方向。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NMT/">NMT</a><a href="/tags/Linguistic-Structure/">Linguistic Structure</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/06/论文笔记：Improved-Neural-Machine-Translation-with-a-Syntax-Aware-Encoder-and-Decoder/" title="论文笔记：Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder" itemprop="url">论文笔记：Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-11-06T09:55:44.000Z" itemprop="datePublished"> Published 2017-11-06</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="1-文章有何贡献？"><a href="#1-文章有何贡献？" class="headerlink" title="1.文章有何贡献？"></a>1.文章有何贡献？</h4><p>一、提出了bidirectional tree encoder，可以同时学会译出语言的序列表达和树状表达特征。之后，解码器利用这些信息进行解码。</p>
<p>二、提出了tree-coverage model, 使得注意力机制更有效地利用了译出语言的句法结构。</p>
<h4 id="2-本文研究的问题有何价值？"><a href="#2-本文研究的问题有何价值？" class="headerlink" title="2.本文研究的问题有何价值？"></a>2.本文研究的问题有何价值？</h4><p>一，在encoder端，对<em>Eriguchi et al. (2016)</em>的树状解码器进行了强化，改成了双方向的，不仅有bottom-up encoder，还有up-down encoder。与基线NMT模型相比，性能有了很大的提升。</p>
<p>二、在decoder端，利用<em>Tu et al. (2016)</em>的coverage模型，将译出端的句法结构整合进注意力机制中去。这种处理，使得性能得到更大的提升。</p>
<h4 id="3-研究问题有什么挑战？"><a href="#3-研究问题有什么挑战？" class="headerlink" title="3.研究问题有什么挑战？"></a>3.研究问题有什么挑战？</h4><p>一、如何充分编码译出端的句法信息？较之之前已有的树状编码器(tree encoder).</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-ac021456b88eaeed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Tree Encoder"></p>
<p>二、直接将树状编码器的各个节点，输入注意力机制后，发现会过度地集中于父节点，而忽略了子节点。导致的结果是，对某些部分的句子进行了重复翻译。如何解决这个问题。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-165ce74906fae653.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Over attention to parent nodes"></p>
<h4 id="4-本文的解决思路？"><a href="#4-本文的解决思路？" class="headerlink" title="4.本文的解决思路？"></a>4.本文的解决思路？</h4><p>对于第一个问题，提出<strong>bidirectional tree encoder</strong>。</p>
<p>当下面的叶节点按照序列顺序进行完了双向LSTM后，拼接特征，输入上一级的父节点，然后以此类推，到达最后的根节点。这是，原来的树状编码器的思路，也就是bottom-up。这样我们每个节点，获得了一个向上的特征向量。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-76377f6fdc6bdb0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Bi-directional Tree Encoder"></p>
<p>而本文更进一步，将bottom-up的结果输入根节点，然后再从上到下，到达各个子节点。这也就是top-down。这样每个节点又获得了一个向下的特征向量。</p>
<p>之后将向上和向下的拼接，就是我们需要的双向特征了。</p>
<p>对于第二个问题，提出了<strong>tree-coverage model</strong>。</p>
<p>其实所谓的coverage就是，在计算当前时序的attention时，考虑之前时序的attention。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-1ed9e9f543969536.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Attention balanced"></p>
<p>具体细节公式参考论文。 </p>
<p><a href="https://arxiv.org/pdf/1707.05436.pdf" target="_blank" rel="noopener">Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Paper-Notes/">Paper Notes</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NMT/">NMT</a><a href="/tags/Linguistic-Structure/">Linguistic Structure</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/10/31/神经机器翻译概览：基准模型与改进（下）/" title="神经机器翻译概览：基准模型与改进（下）" itemprop="url">神经机器翻译概览：基准模型与改进（下）</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Andy Yang" target="_blank" itemprop="author">Andy Yang</a>
		
  <p class="article-time">
    <time datetime="2017-10-31T02:02:29.000Z" itemprop="datePublished"> Published 2017-10-31</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="神经机器翻译概览：基准模型与改进（下）"><a href="#神经机器翻译概览：基准模型与改进（下）" class="headerlink" title="神经机器翻译概览：基准模型与改进（下）"></a>神经机器翻译概览：基准模型与改进（下）</h2><blockquote>
<p>光看下篇小心变成梅超风，上篇：</p>
<p><a href="https://www.jianshu.com/p/546750a32c92" target="_blank" rel="noopener">神经机器翻译概览：基准模型与改进（上）</a></p>
</blockquote>
<p>之前在上篇主要提到了神经机器翻译的基准模型，序列到序列+注意力机制。</p>
<p>还从多个方面谈到了怎么对基准模型进行改进，其中包括：</p>
<ul>
<li>利用多个模型的<strong>集成解码</strong></li>
<li>怎么处理<strong>庞大的词汇量</strong></li>
<li>如何使用<strong>单语言数据</strong></li>
</ul>
<p>上面这三个都没有触及到，对基准模型的修改，更多是集成和利用数据。</p>
<p>在下篇中，我们开始讨论</p>
<ul>
<li>怎么利用<strong>深层模型</strong>，改进编码和解码器</li>
<li>怎么利用<strong>引导对齐 (Alignment) </strong>训练，加强注意力机制</li>
<li>怎么加入<strong>覆盖 (Coverage)</strong> 技巧，保证不过度翻译</li>
</ul>
<p>同时进一步讨论怎么利用数据，其中包括</p>
<ul>
<li>如何用<strong>域适应</strong> (Domain Adaption) 技巧，利用其它域的数据来帮助训练只有少量数据的任务</li>
<li>如何利用除了词以外的<strong>语言学标记</strong>，来加强翻译</li>
<li>如何处理<strong>多语言对</strong>的问题，甚至是利用多语言对实现零样本学习</li>
</ul>
<h3 id="深层模型"><a href="#深层模型" class="headerlink" title="深层模型"></a>深层模型</h3><p>对于神经网络模型，其中最值得探索的便是其中的深层模型，这也是深度学习在探索的。因为根据不同连接方式，就可以得到不同的模型架构，而这些不同架构分别在处理特定问题是会有很好的效果。</p>
<p>比如计算机视觉的话，之前也提到过的<a href="https://www.jianshu.com/p/841ac51c7961" target="_blank" rel="noopener">CNN里面各种变种</a>，ResNet还有InceptNet这样的通过不同的连接技巧获得不同构架变种。</p>
<h4 id="深层解码器"><a href="#深层解码器" class="headerlink" title="深层解码器"></a>深层解码器</h4><p>对于解码器端，主要是对循环神经网络（RNN）的两种链接方式的应用。</p>
<p>第一种连接方式，<strong>堆叠（Stacked）RNN</strong>，也就是一般常见的连接方式。<strong>当前隐态是由同一个时序前一个层的隐态和前一个时序同一个层的隐态决定的</strong>。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-2253286ca6904fee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="两种连接"></p>
<p>第二种连接，<strong>深层过渡（Transition）RNN</strong>，这种是<strong>当前时序的第一层隐态由前一个时序的最后一层隐态决定，而其他的隐态则只由前一层的隐态决定</strong>。</p>
<p>在现实应用中可以把两个技巧结合起来使用，至于到底怎么组合更好，现在还没有定论，还有待探索。实际上很多模型中就只用了堆叠模型，如果要用上两个的话，这里可以给出一个例子。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-e4eba49c74c019e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这个模型里面，有些层用堆叠RNN里的处理方法，而有的层则是用过渡RNN的处理方法。</p>
<h4 id="深层编码器"><a href="#深层编码器" class="headerlink" title="深层编码器"></a>深层编码器</h4><p>编码器跟解码器一样，也可以利用上述的不同连接技巧。</p>
<p>比起解码器，因为编码器更容易利用句子的双向信息，所以更重要的是，应该试着应用不同的连接技巧，获得更多的双向信息。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-8babc056e64cc952.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Alternating RNN"></p>
<p>这里举一个例子，一个叫做<strong>交替 (Alternating) RNN**</strong>的**模型，从第一层开始往上，首先是从左到右，之后从右到左，之后再从左到右… 这样子的交替运行。</p>
<p>除了上面说的这些，对于深层的编码解码器，当然也可以用上一般深层模型中的一些技巧，比如说残差连接。</p>
<h3 id="引导对齐-Guided-Alignment-训练"><a href="#引导对齐-Guided-Alignment-训练" class="headerlink" title="引导对齐 (Guided Alignment) 训练"></a>引导对齐 (Guided Alignment) 训练</h3><p>首先如之前基准模型时介绍的，模型中注意力机制的主要作用，是决定源语言句子和目标语言句子之间词对应关系。比如说通过注意力机制，模型知道德语里面的词Bücherregal，对应英语里的book shelf。</p>
<p>而这样的对应关系是通过在大量数据上训练，模型自己学会的，但实际情况中，有时注意力机制可能学习的<strong>并不是对齐方式</strong>，而是其他东西。比如说下图就是对齐和注意力机制的对比。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-20b3f0e49c7d824f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>图中蓝色的框是标准的对齐方法，而绿色部分则是注意力机制学习的对齐，我们会发现在有些地方两者很不一致。所以这也表示可能在这里注意力机制学习的就不是词对齐，那能不能让注意力机制学习标准的对齐方式呢？</p>
<p>当然可以。就像翻译时有标准的翻译数据一样，对齐的话，如果事先有标准的对齐数据，就<strong>能用标准对齐方式来作为目标训练注意力机制</strong>，使得它输出的结果和标准对齐方式一样。</p>
<h3 id="模型的覆盖-Coverage"><a href="#模型的覆盖-Coverage" class="headerlink" title="模型的覆盖(Coverage)"></a>模型的覆盖(Coverage)</h3><p>现在的神经网络翻译模型还有一个很大的问题，过度翻译 (Over-translation)和翻译不足 (Under-translation) 。</p>
<p>有时候注意力机制<strong>把注意力都只放在某些重要词上</strong>，所以会出现翻译时对重要的词进行重复翻译，也就是突然结巴了；也会对有些本因翻译的词视而不见。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-bde27df49b4e48a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Social Housing 过度注意，导致翻译不足"></p>
<p>而解决这个问题的方法就如标题，要保重翻译时对输入的所有词有一个全面的覆盖，使得所有词得到适当的翻译。</p>
<h4 id="在翻译阶段设置约束保证强制覆盖"><a href="#在翻译阶段设置约束保证强制覆盖" class="headerlink" title="在翻译阶段设置约束保证强制覆盖"></a>在翻译阶段设置约束保证强制覆盖</h4><p>第一个方法，我们可以设计一个评价函数。当束搜索（Beam Search）给出几个备选翻译时，根据每个备选翻译的覆盖程度给出一定的评分。</p>
<p>实际上也就是<strong>人为地设计一个对更标准翻译评估的函数，来引导解码器的翻译有更好的覆盖</strong>。</p>
<h4 id="覆盖模型"><a href="#覆盖模型" class="headerlink" title="覆盖模型"></a>覆盖模型</h4><p>还有一种方法，叫做覆盖（Coverage）模型。</p>
<p>首先之所以模型不能完成全面的覆盖，第一，最初输入的信息在经过几个时序传输后，信息并不能被有效保存下来；第二，每次翻译利用注意力机制来查看源语言时，都只与当前的翻译中的注意力有关，但却不知道之前的翻译词用到过的注意力，也就是说<strong>即使之前的翻译已经将注意力放在一个词上并给出了翻译，当前词也不知道</strong>。</p>
<p>那么解决方案也很直观，那就是让当前翻译知道之前用到过的注意力。</p>
<p>比如说可以把每个时序获得的注意力向量作为输入，输进RNN网络。而在每一个时序上，输入是对之前注意力的总结，还有当前时序用正常方法获得的注意力，之后输出要用到的注意力向量。</p>
<p>于是当前用到的注意力向量就是来自于历史注意力和当前注意力，可以避免过度翻译。</p>
<h4 id="Fertility-可繁殖性"><a href="#Fertility-可繁殖性" class="headerlink" title="Fertility (可繁殖性)"></a>Fertility (可繁殖性)</h4><p>对于覆盖模型还可以利用fertility来进行辅助，fertility指的就是<strong>一个源语言词可以翻译成目标语言词的个数</strong>，比如说德语的natuerlich译成英文就是两个词in fact，那么natuerlich的fertility就是2。</p>
<p>通过预测fertility就可以比较方便地知道当前词应该翻译成多少个词，如果达到了，那就把注意力集中在其他词。</p>
<p>Fertility也有很多其他应用，比如说<a href="https://einstein.ai/research/non-autoregressive-neural-machine-translation" target="_blank" rel="noopener">最近Salesforce利用fertility实现了完全并行翻译</a>，而不是像RNN解码器一样得一个个解码。</p>
<p>但实际上我认为fertility有很多局限性，比如说实际翻译中有很多种译法，那么这些对于的fertility就都不一样，也就是说某个词的fertility不唯一。</p>
<h3 id="域适应-Domain-Adaption"><a href="#域适应-Domain-Adaption" class="headerlink" title="域适应 (Domain Adaption)"></a>域适应 (Domain Adaption)</h3><p>和很多其他领域一样，在机器翻译领域里域适应问题也是个大问题。</p>
<p>首先什么是域（Domain）? 比较直观的解释是，<strong>某个类型的数据</strong>。比如说，情感分析里亚马逊的商品评论数据就根据商品种类分为：家电、书籍、衣物等多个种类，那么我们可以把这些当成不同的域。</p>
<p>机器翻译中和域相关的问题是，大部分并行数据 (Parallel Data) 都来自于国际性的官方文档 (Europarl)，或者是字幕 (<a href="https://wit3.fbk.eu/" target="_blank" rel="noopener">WIT3</a>)。</p>
<p>而像是那种日常聊天的并行数据却很少，因此如果用提说到的数据训练机器翻译系统，然后用它来翻译聊天的语言的话，那么效果会大打折扣。这是因为<strong>域的不吻合 (Domain Mismatch)</strong> 导致的，为了解决这个问题，就需要域适应技巧了。</p>
<p>通常的域适应问题是这样的，假设有一组和目标任务相关的数据，这个叫做<strong>域内数据 (in-domain data)</strong>，同时也有一组和目标任务不是那么相关的数据，这个叫它<strong>域外数据 (out-of-domain data)</strong>。通常，域内数据太少了，而域外数据比较充足。</p>
<p>当然，域内域外的说法并不是绝对的，而是根据当前目标任务而决定的。</p>
<p>首先来说说两个通常的方案吧。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-9a8d92d1869a379f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>第一，<strong>迁移学习</strong>。就跟在预训练好的ImageNet分类器上用很少数据训练高性能分类器一样，首先先在大量的一般数据上训练出一个神经机器翻译系统，然后再用少量的域内数据进行继续训练。</p>
<p>这种情况下，模型就不光能从大量的一般数据中获得知识，之后也会集中在域内数据的知识上。事实上，这个方案在用域内数据训练阶段，收敛会很快，可以得到不错的域内模型。</p>
<p>第二个，<strong>多域集成学习</strong>，比起第一个用到的就不是那么多了。上篇里也讲过集成学习，这里也就是在不同的域里面训练出多个模型，之后用这多个模型进行集成解码。如果想要再进行微调，可以给予每个模型一定的权重。</p>
<p>之后来看看，在实际应用中会碰到的特殊情况吧。</p>
<h4 id="从大量数据中采样域内数据"><a href="#从大量数据中采样域内数据" class="headerlink" title="从大量数据中采样域内数据"></a>从大量数据中采样域内数据</h4><p>在实际应用中有时会出现的情况是，<strong>域内数据太少</strong>。即使利用上面提到的第一种迁移学习的方法，也会因为数据过少的原因而过拟合 (overfitting)。</p>
<p>为了避免过拟合，只能人为的来增加更多的域内数据了。其中一个方法是，<strong>从一个有着大量一般数据的数据集中挑出与域内数据最接近的数据</strong>。</p>
<p>具体方法也并不是太难，只要先分别训练出域内域外的源和目标语言的4个语言模型，这里需要用到四个单语言数据。</p>
<p>之后对大量并行数据里面的每对数据进行相关性评分，与域内数据相像的得到比较高的评分，之后把评分高的挑出来就好了。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-eb65626ba90aed23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>最后把采样出来的数据和已有数据合并，就可以用来训练目标模型了。</p>
<h4 id="只有域内单语言数据"><a href="#只有域内单语言数据" class="headerlink" title="只有域内单语言数据"></a>只有域内单语言数据</h4><p>实际应用中还有一种情况是，根本就没有域内的并行数据，但是有单语言数据。</p>
<p>第一个解决方案，就像上面提到的一样，先用单语言数据训练语言模型，之后对大量数据进行采样获得域内数据。</p>
<p>第二个方案则是，<strong>合成数据</strong>。首先利用域外数据训练出一个模型，然后用这个模型来回译已有域内单语言数据，之后利用这些数据来进行迁移学习的第二阶段的训练。</p>
<h4 id="多领域模型"><a href="#多领域模型" class="headerlink" title="多领域模型"></a>多领域模型</h4><p>最后一种情况，已经有一些分类分得很清的数据了，可以清晰地知道它们属于不同的域。</p>
<p>这种情况，可以首先在各个域训练出翻译模型，然后再训练出一个文本分类器。</p>
<p>之后，进行翻译时，<strong>先对当前文本进行文本分类</strong>，搞清楚它到底是属于哪个域。之后，挑选<strong>其所属域的翻译模型，对其进行翻译</strong>。这样子也就不用麻烦地进行域适应了。</p>
<h3 id="利用语言学标记"><a href="#利用语言学标记" class="headerlink" title="利用语言学标记"></a>利用语言学标记</h3><p>以上谈到的各种技巧，都是从词语层面上进行翻译的。但实际上，在语言学中每个词除了本身作为一个词，还会有着各种语言学的标记。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-866f5705d2cfe349.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>一般会用到的标记，从底层到上层，常用到的分别有形态学(Morphology)标记、词性(POS, part of speech)标记、依存(Dependency)和成分(Constituent)标记、语义(Semantic)标记…</p>
<p>在机器翻译中对这些语言学知识的利用，主要可以分为三个方面。</p>
<ol>
<li>利用输入句子的语言学标记</li>
<li>利用输出句子的语言学标记</li>
<li>建立利用了语言学结构的模型</li>
</ol>
<h4 id="输入端的语言学标记"><a href="#输入端的语言学标记" class="headerlink" title="输入端的语言学标记"></a>输入端的语言学标记</h4><p>首先对于输入端，比较容易想到的一种利用方法，是除了给词建立一个词向量表外，同时<strong>也给语言学标记分别建立向量表</strong>。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-f96623de57ab4d4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="the girl watched attentively the beautiful fireflies 的各种语言学标记"></p>
<p>之后训练时，每次输入一个词还有其对应的语言学标记，就分别进行查表，之后把这些特征向量拼接起来，作为一个词的向量输入编码器。</p>
<p>这个技巧因为简单的原因，所以在很多已有神经机器翻译工具包里都得到了实现。</p>
<h4 id="输出端的语言学标记"><a href="#输出端的语言学标记" class="headerlink" title="输出端的语言学标记"></a>输出端的语言学标记</h4><p>输出端这边，首先也可以像输入端一样，建立语言学标记的向量表，然后查表，拼接起来。但是，对于输出端我们还能够进行些更复杂的改变，比如说<strong>同时进行语言学结构和目标词的输出</strong>，这样可以利用语言学的结构引导输出句子的句法正确性。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-335697e0b9ec3c27.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="线性化句法树"></p>
<p>这里举一个最简单的例子，就是<strong>将目标句子的句法树 (Syntax tree) 线性化，从树结构变成线性结构，然后中间同时插入预测词。训练的时候，预测的不再单单是目标句子了，而是这个线性化了的句法树</strong>。</p>
<p>除了这样子的简单线性化以外，还有一些其他论文，同时进行句法结构预测和句子的预测进行多任务学习，也取得了比较好的效果。</p>
<h4 id="语言结构化的模型"><a href="#语言结构化的模型" class="headerlink" title="语言结构化的模型"></a>语言结构化的模型</h4><p>上面提到的所有情况，都还是序列到序列的翻译。因为在上面的这种翻译方法看来，语言不过就是一串字符排成的序列，输入一段序列，然后得到另一段序列**。</p>
<p>但是实际上我们是知道的，语言并不仅仅只是序列，而是递归的，像树状一样层层展开。</p>
<p>所以现在神经机器翻译里一个很火的研究方向就是，如何<strong>从语言结构到语言结构，然后进行翻译</strong>。目前还没有能够做到树到树结构的翻译，但是在源或目标语言一端利用树状结构，已经有一些成果了。</p>
<h3 id="多语言对"><a href="#多语言对" class="headerlink" title="多语言对"></a>多语言对</h3><p>最后，在把基本模型几乎方方面面提高进行了讨论之后，再来看看多语言对。因为世界上并不是只有两种语言，而是很多种语言，有些语言对有足够数据，但也有很多语言对并没有足够数据。</p>
<p>但是看现在Google的翻译系统，不是可以对应很多很多语言吗？</p>
<p>这是因为谷歌的神经网络翻译系统在一定程度上实现了，<strong>零样本学习 (Zero-shot Learning)</strong>，当然也同时用了很多其他技巧。</p>
<blockquote>
<p>所谓零样本学习，就是指对于某个任务，没有这个任务的训练数据，但是仍然可以训练出相应的模型。在现实生活中，人类有时就会大量使用零样本学习。</p>
<p>Quora链接：<a href="https://www.quora.com/What-is-zero-shot-learning" target="_blank" rel="noopener">https://www.quora.com/What-is-zero-shot-learning</a></p>
</blockquote>
<h4 id="多输入语言"><a href="#多输入语言" class="headerlink" title="多输入语言"></a>多输入语言</h4><p>首先如果有多个输入语言，而只有一个输出语言，怎么进行训练呢？</p>
<p>方法很想当然，直接把这些数据放在一起训练，输入端不同语言共享一个词汇表。每次输入句子的时候<strong>快速识别出输入句子所属语言，然后调用相应的词向量</strong>。</p>
<h4 id="多输出语言"><a href="#多输出语言" class="headerlink" title="多输出语言"></a>多输出语言</h4><p>对于多个输出语言，也可以用同样的技巧，把数据放在一起进行训练，多个语言共享词汇表，</p>
<p>但是模型怎么知道想翻译成什么语言呢，输入端还能够自动检测，但是输出端就不行呢，那就直接由我们告诉它好了。于是可以<strong>在输入句子前加上一个标签，来告诉系统想把当前句子翻译成什么语言</strong>。谷歌翻译系统中，这个在最开始我们选择相应语言的时候就会告诉系统。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-1790eac59459f18d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>虽然这个方法看起来很天然，但是却非常有效。而且更出乎人意料的是，用这个方法可以实现零样本学习。</p>
<p>比如说现在有<strong>德语-英语</strong>、<strong>法语-英语</strong>、还有<strong>法语-西班牙语</strong>三个语言对的数据。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-663b111296be1767.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>利用上述方法，把这些数据放在一起训练一个模型。之后翻译的时候，先给源语言句子加上一个目标语言的标签，然后输入系统就可以得到结果。</p>
<p>这里神奇的事情是，如果把一句德语句子作为输入，然后在它前面加上目标语言是西班牙语的标签。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/4787675-f7093df6e016561d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>一般来说，因为训练的时候根本就没有德语-西班牙语数据，那么也就不会成功。但结果是，居然翻译成功了！</p>
<p>也就是说在<strong>根本没有某个语言对训练的情况下，而模型进行了该语言对的翻译</strong>，也就是零样本学习。而且结果显示翻译效果还挺好的。</p>
<p>对于人类这样的零样本学习显得稀疏平常，近似本能。你既然会德语-英语之间翻译，也会英语-西班牙语翻译，那会德语-西班牙语翻译不就很正常吗。</p>
<p>但是对于以往的机器翻译系统，往往是你给它什么训练语言对，它也就只会这个语言对的翻译。</p>
<p>而这个系统的成功就意味着，对于所有不同语言，这里可能确实存在着一个中间语言 (Interlingua)，或者说是中间表达。模型首先把输入语言转换成中间表达，然后翻译目标语言，这样子就能很自然地实现零样本学习。</p>
<h4 id="分享部件"><a href="#分享部件" class="headerlink" title="分享部件"></a>分享部件</h4><p>当然，上述的模型过于简单粗暴，就是把什么都丢进一个万能模型，然后让它自己训练。</p>
<p>所以如果想要更加仔细地考虑怎么处理输入输出语言，我们可以试着为每个语言对训练一个模型，但是分享中间不同的部件。所以具体方案就如下。</p>
<ol>
<li>对于有相同输入语言的模型，分享编码器。</li>
<li>对于有相同输出语言的模型，分享解码器。</li>
<li>而注意力机制则是所有模型进行共享。</li>
</ol>
<p>以上就是目前大部分对基准模型进行提升的技巧了，实际上最新的各种技巧也不断在出现，这里肯定有很多没有覆盖到的。但里提到的是已经被证实比较有效，而且大部分已经能实际应用的方法。</p>
<h2 id="替代模型"><a href="#替代模型" class="headerlink" title="替代模型"></a>替代模型</h2><h3 id="卷积模型"><a href="#卷积模型" class="headerlink" title="卷积模型"></a>卷积模型</h3><h3 id="卷积-注意力"><a href="#卷积-注意力" class="headerlink" title="卷积+注意力"></a>卷积+注意力</h3><h3 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h3><h2 id="当前的挑战（NMT和PSMT的比较）"><a href="#当前的挑战（NMT和PSMT的比较）" class="headerlink" title="当前的挑战（NMT和PSMT的比较）"></a>当前的挑战（NMT和PSMT的比较）</h2><h3 id="域误配问题"><a href="#域误配问题" class="headerlink" title="域误配问题"></a>域误配问题</h3><p>NMT更加不能适应域变换。</p>
<h3 id="训练数据量问题"><a href="#训练数据量问题" class="headerlink" title="训练数据量问题"></a>训练数据量问题</h3><p>有足够多的数据的话，NMT可以达到很好的结果。</p>
<h3 id="噪声问题"><a href="#噪声问题" class="headerlink" title="噪声问题"></a>噪声问题</h3><p>NMT更加不能抵抗数据中的噪音。</p>
<h3 id="词匹配问题"><a href="#词匹配问题" class="headerlink" title="词匹配问题"></a>词匹配问题</h3><h3 id="束搜索-Beam-Search"><a href="#束搜索-Beam-Search" class="headerlink" title="束搜索(Beam Search)"></a>束搜索(Beam Search)</h3><p>Fast Alignment</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Natural-Language-Processing/">Natural Language Processing</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/NLP/">NLP</a><a href="/tags/机器翻译/">机器翻译</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







</div>
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/Natural-Language-Processing/" title="Natural Language Processing">Natural Language Processing<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Paper-Notes/" title="Paper Notes">Paper Notes<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/语言学/" title="语言学">语言学<sup>1</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/NMT/" title="NMT">NMT<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Linguistic-Structure/" title="Linguistic Structure">Linguistic Structure<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/NLP/" title="NLP">NLP<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/机器翻译/" title="机器翻译">机器翻译<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/RNN/" title="RNN">RNN<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/恶搞/" title="恶搞">恶搞<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/LSTM/" title="LSTM">LSTM<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://www.jianshu.com/u/2bce591750a0" target="_blank" title="简书(坂本龙一)">简书(坂本龙一)</a>
            
          </li>
        
          <li>
            
            	<a href="https://upload-images.jianshu.io/upload_images/4787675-731072fb09d7426a.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" title="公众号(安迪的写作间)">公众号(安迪的写作间)</a>
            
          </li>
        
          <li>
            
            	<a href="https://medium.com/andy-yangz" target="_blank" title="Medium">Medium</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Andy Yang in JAIST. <br/>
			This is my blog, no matter you believe it or not, anyway I don&#39;t believe it.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		<a href="https://github.com/https://github.com/andy-yangz" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2019 
		
		<a href="/about" target="_blank" title="Andy Yang">Andy Yang</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
